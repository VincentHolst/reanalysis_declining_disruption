{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15385705571540897\n",
      "0.9460157668286039\n"
     ]
    }
   ],
   "source": [
    "#Note: robust standard errors are obtained via Stata\n",
    "#See Stata files\n",
    "#Python code is for figures and open-source reproducibility\n",
    "import config_declining_disruption as config\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "\n",
    "from sklearn import config_context, linear_model #we use scikit-learn 1.2.0\n",
    "\n",
    "\n",
    "###Data prep - takes 5 min\n",
    "#Read data\n",
    "data = pd.read_csv(config.DATA_PATH+\"SciSciNet_df.csv\")\n",
    "\n",
    "#Drop rows with missing values\n",
    "data.dropna(subset=[\"cd_5\", \"Year\", \"Field_Name\", \"Team_Size\"], inplace=True)\n",
    "\n",
    "#Create dummies\n",
    "grant_year_dummies = pd.get_dummies(data[\"Year\"], prefix=\"Year\")\n",
    "grant_year_dummies.drop(\"Year_1944.0\", axis=1, inplace=True)\n",
    "\n",
    "subfield_dummies = pd.get_dummies(data[\"Field_Name\"], prefix=\"Field\")\n",
    "subfield_dummies.drop(\"Field_Art\", axis=1, inplace=True)\n",
    "\n",
    "#Create control variables\n",
    "data[\"no_of_papers_subfield_t\"] = data.groupby(\n",
    "    [\"Year\", \"Field_Name\"]\n",
    ")[\"PaperID\"].transform(\"size\")\n",
    "\n",
    "data[\"no_of_references_subfield_t\"] = data.groupby(\n",
    "    [\"Year\", \"Field_Name\"]\n",
    ")[\"references\"].transform(\"sum\")\n",
    "\n",
    "data[\"no_of_authors_subfield_t\"] = data.groupby(\n",
    "    [\"Year\", \"Field_Name\"]\n",
    ")[\"Team_Size\"].transform(\"sum\")\n",
    "\n",
    "data[\"no_of_references_mean_subfield_t\"] = data[\"no_of_references_subfield_t\"] / data[\"no_of_papers_subfield_t\"]\n",
    "data[\"no_of_authors_mean_subfield_t\"] = data[\"no_of_authors_subfield_t\"] / data[\"no_of_papers_subfield_t\"]\n",
    "\n",
    "#New control\n",
    "data[\"bin_0\"] = data[\"references\"].apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "#Data\n",
    "x = pd.concat(\n",
    "    [\n",
    "        grant_year_dummies,\n",
    "        subfield_dummies,\n",
    "        data[\"references\"],\n",
    "        data[\"no_of_authors_mean_subfield_t\"],\n",
    "        data[\"no_of_references_mean_subfield_t\"],\n",
    "        data[\"no_of_papers_subfield_t\"],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "x_0 = pd.concat(\n",
    "    [\n",
    "        grant_year_dummies,\n",
    "        subfield_dummies,\n",
    "        data[\"references\"],\n",
    "        data[\"no_of_authors_mean_subfield_t\"],\n",
    "        data[\"no_of_references_mean_subfield_t\"],\n",
    "        data[\"no_of_papers_subfield_t\"],\n",
    "        data[\"bin_0\"],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "y = data[\"cd_5\"]\n",
    "\n",
    "###Regression - takes 5 mins with these optimizations\n",
    "#Large data set - use cholesky solver\n",
    "# https://github.com/scikit-learn/scikit-learn/issues/13923\n",
    "# https://github.com/scikit-learn/scikit-learn/pull/22940\n",
    "with config_context(assume_finite=True):\n",
    "    model_1 = linear_model.Ridge(alpha=1e-9, solver=\"cholesky\").fit(x, y)\n",
    "\n",
    "with config_context(assume_finite=True):\n",
    "    model_2 = linear_model.Ridge(alpha=1e-9, solver=\"cholesky\").fit(x_0, y)\n",
    "\n",
    "###Compute residuals\n",
    "data[\"preds_1\"] = model_1.predict(x)\n",
    "data[\"preds_2\"] = model_2.predict(x_0)\n",
    "\n",
    "data[\"residuals_1\"] = y - data[\"preds_1\"]\n",
    "residuals_1=data[\"residuals_1\"].to_numpy()\n",
    "data[\"residuals_2\"] = y - data[\"preds_2\"]\n",
    "residuals_2=data[\"residuals_2\"].to_numpy()\n",
    "\n",
    "#Print Adjusted R-squared of the models\n",
    "print(1-(1-model_1.score(x,y))*((len(x)-1)/(len(x)-len(x.columns)-1)))\n",
    "print(1-(1-model_2.score(x_0,y))*((len(x_0)-1)/(len(x_0)-len(x_0.columns)-1)))\n",
    "\n",
    "#Compute margins - takes 120 mins\n",
    "# https://www.stata.com/meeting/germany13/abstracts/materials/de13_jann.pdf\n",
    "#See slides 14-15\n",
    "#Make predictions with original data, but for each year set grant_year_i = 1\n",
    "x[grant_year_dummies.columns] = 0\n",
    "x_0[grant_year_dummies.columns] = 0\n",
    "\n",
    "margins = pd.DataFrame(\n",
    "    {\n",
    "        \"Years\": list(range(int(data[\"Year\"].min()), int(data[\"Year\"].max()+1)))\n",
    "    }\n",
    ")\n",
    "\n",
    "for i in range(int(data[\"Year\"].min()), int(data[\"Year\"].max()+1)):\n",
    "\n",
    "    if i > 1944:\n",
    "        x[f\"Year_{i}.0\"] = 1\n",
    "        x_0[f\"Year_{i}.0\"] = 1\n",
    "   \n",
    "    margins.loc[margins[\"Years\"] == i, \"margins_original\"] = model_1.predict(x).mean()\n",
    "    margins.loc[margins[\"Years\"] == i, \"margins_zero_refs\"] = model_2.predict(x_0).mean()\n",
    "\n",
    "    if i > 1944:\n",
    "        x[f\"Year_{i}.0\"] = 0\n",
    "        x_0[f\"Year_{i}.0\"] = 0\n",
    "\n",
    "del model_1, model_2, x, x_0\n",
    "gc.collect()\n",
    "\n",
    "#Save margins and the residuals\n",
    "margins.to_csv(config.DATA_PATH+\"SciSciNet_margins.csv\", index=False)\n",
    "np.save(config.DATA_PATH + \"patentsview_residuals_1.npy\", residuals_1)\n",
    "np.save(config.DATA_PATH + \"patentsview_residuals_2.npy\", residuals_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15991098025272588\n",
      "0.16620440721129714\n",
      "0.16819010088222153\n",
      "0.16831851544344134\n",
      "0.16784256685955745\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"bin_1\"] = data[\"references\"].apply(lambda x: 1 if x == 1 else 0)\n",
    "data[\"bin_2\"] = data[\"references\"].apply(lambda x: 1 if x == 2 else 0)\n",
    "data[\"bin_3\"] = data[\"references\"].apply(lambda x: 1 if x == 3 else 0)\n",
    "data[\"bin_4\"] = data[\"references\"].apply(lambda x: 1 if x == 4 else 0)\n",
    "data[\"bin_5\"] = data[\"references\"].apply(lambda x: 1 if x == 5 else 0)\n",
    "\n",
    "x_1 = pd.concat(\n",
    "    [\n",
    "        grant_year_dummies,\n",
    "        subfield_dummies,\n",
    "        data[\"references\"],\n",
    "        data[\"no_of_authors_mean_subfield_t\"],\n",
    "        data[\"no_of_references_mean_subfield_t\"],\n",
    "        data[\"no_of_papers_subfield_t\"],\n",
    "        data[\"bin_1\"],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "with config_context(assume_finite=True):\n",
    "    model_3 = linear_model.Ridge(alpha=1e-9, solver=\"cholesky\").fit(x_1, y)\n",
    "\n",
    "#Print Adjusted R-squared of the model\n",
    "print(1-(1-model_3.score(x_1,y))*((len(x_1)-1)/(len(x_1)-len(x_1.columns)-1)))\n",
    "\n",
    "del model_3, x_1\n",
    "gc.collect()\n",
    "\n",
    "x_2 = pd.concat(\n",
    "    [\n",
    "        grant_year_dummies,\n",
    "        subfield_dummies,\n",
    "        data[\"references\"],\n",
    "        data[\"no_of_authors_mean_subfield_t\"],\n",
    "        data[\"no_of_references_mean_subfield_t\"],\n",
    "        data[\"no_of_papers_subfield_t\"],\n",
    "        data[\"bin_2\"],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "with config_context(assume_finite=True):\n",
    "    model_4 = linear_model.Ridge(alpha=1e-9, solver=\"cholesky\").fit(x_2, y)\n",
    "\n",
    "#Print Adjusted R-squared of the model\n",
    "print(1-(1-model_4.score(x_2,y))*((len(x_2)-1)/(len(x_2)-len(x_2.columns)-1)))\n",
    "\n",
    "del model_4, x_2\n",
    "gc.collect()\n",
    "\n",
    "x_3 = pd.concat(\n",
    "    [\n",
    "        grant_year_dummies,\n",
    "        subfield_dummies,\n",
    "        data[\"references\"],\n",
    "        data[\"no_of_authors_mean_subfield_t\"],\n",
    "        data[\"no_of_references_mean_subfield_t\"],\n",
    "        data[\"no_of_papers_subfield_t\"],\n",
    "        data[\"bin_3\"],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "with config_context(assume_finite=True):\n",
    "    model_5 = linear_model.Ridge(alpha=1e-9, solver=\"cholesky\").fit(x_3, y)\n",
    "\n",
    "#Print Adjusted R-squared of the model\n",
    "print(1-(1-model_5.score(x_3,y))*((len(x_3)-1)/(len(x_3)-len(x_3.columns)-1)))\n",
    "\n",
    "del model_5, x_3\n",
    "gc.collect()\n",
    "\n",
    "x_4 = pd.concat(\n",
    "    [\n",
    "        grant_year_dummies,\n",
    "        subfield_dummies,\n",
    "        data[\"references\"],\n",
    "        data[\"no_of_authors_mean_subfield_t\"],\n",
    "        data[\"no_of_references_mean_subfield_t\"],\n",
    "        data[\"no_of_papers_subfield_t\"],\n",
    "        data[\"bin_4\"],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "with config_context(assume_finite=True):\n",
    "    model_6 = linear_model.Ridge(alpha=1e-9, solver=\"cholesky\").fit(x_4, y)\n",
    "\n",
    "#Print Adjusted R-squared of the model\n",
    "print(1-(1-model_6.score(x_4,y))*((len(x_4)-1)/(len(x_4)-len(x_4.columns)-1)))\n",
    "\n",
    "del model_6, x_4\n",
    "gc.collect()\n",
    "\n",
    "x_5 = pd.concat(\n",
    "    [\n",
    "        grant_year_dummies,\n",
    "        subfield_dummies,\n",
    "        data[\"references\"],\n",
    "        data[\"no_of_authors_mean_subfield_t\"],\n",
    "        data[\"no_of_references_mean_subfield_t\"],\n",
    "        data[\"no_of_papers_subfield_t\"],\n",
    "        data[\"bin_5\"],\n",
    "    ],\n",
    "    axis=1,\n",
    ")\n",
    "\n",
    "with config_context(assume_finite=True):\n",
    "    model_7 = linear_model.Ridge(alpha=1e-9, solver=\"cholesky\").fit(x_5, y)\n",
    "\n",
    "#Print Adjusted R-squared of the model\n",
    "print(1-(1-model_7.score(x_5,y))*((len(x_5)-1)/(len(x_5)-len(x_5.columns)-1)))\n",
    "\n",
    "del model_7, x_5\n",
    "gc.collect()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
